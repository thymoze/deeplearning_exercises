{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - DL Tutorial 08\n",
    "\n",
    "### Student names:  Franz Schulze, Benedikt Bauer, David Heim\n",
    "\n",
    "Submit you solution by 30 June 23:59 to manuel.milling@informatik.uni-augsburg.de or maurice.gerczuk@informatik.uni-augsburg.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "w2v_embedding_file = \"./res/data/embeddings/word2vec-40k-wiki-news-300d.vec\"#\"./res/data/embeddings/word2vec-40k-wiki-news-300d.vec\"\n",
    "ewe_embedding_file = \"./res/data/embeddings/ewe-40k-300d.vec\"\n",
    "\n",
    "train_tsv = \"./res/data/isear/train.tsv \"\n",
    "val_tsv = \"./res/data/isear/val.tsv\"\n",
    "test_tsv = \"./res/data/isear/test.tsv\"\n",
    "\n",
    "oov_id=1\n",
    "pad_id=0\n",
    "seq_length=128\n",
    "batch_size=32\n",
    "epochs=5\n",
    "\n",
    "lr=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load word2vec embedding matrix and create word-index-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_emb_matrix:\t\t(40002, 300)\n",
      "w2v_word2idx shape:\t40000\n"
     ]
    }
   ],
   "source": [
    "def read_embedding_matrix(embedding_file, init_random: bool = False):\n",
    "    read_content: list[str] = []\n",
    "    \n",
    "    # This seems a rather lenghty approach\n",
    "    with open(embedding_file, 'rb') as vecfile:\n",
    "        for line in vecfile.readlines():\n",
    "            read_content.append(str(line))\n",
    "\n",
    "    content: list[list[str]]\n",
    "    content = list(map(lambda line: line.split(' '), read_content))\n",
    "    \n",
    "    labels_as_list = [row.pop(0) for row in content]\n",
    "    labels_as_list = [label[2:] for label in labels_as_list]\n",
    "\n",
    "    label_dict: dict[str, int] = {}\n",
    "    temp_label_dict = [{value: index + 2} for index, value in enumerate(labels_as_list)]\n",
    "    for key_value in temp_label_dict:\n",
    "        label_dict.update(key_value)\n",
    "\n",
    "    embedding_matrix: np.ndarray = None\n",
    "\n",
    "    if init_random:\n",
    "        embedding_matrix = np.random.randn(len(content), len(content[0]))\n",
    "    else:\n",
    "        # for the embedding matrix this is not really necessary\n",
    "        content = [[string.replace('\\\\n', '').replace('\\'', '').replace('\\\"', '') for string in row] for row in content]\n",
    "        embedding_matrix = np.array(content, dtype=np.float32)\n",
    "\n",
    "    matrix_padding = np.zeros(embedding_matrix.shape[1])\n",
    "    oov_padding = np.mean(embedding_matrix, axis=0)\n",
    "    embedding_matrix = np.insert(embedding_matrix, 0, matrix_padding, 0)\n",
    "    embedding_matrix = np.insert(embedding_matrix, 1, oov_padding, 0)\n",
    "\n",
    "    return embedding_matrix, label_dict\n",
    "    \n",
    "\n",
    "w2v_emb_matrix, w2v_word2idx = read_embedding_matrix(w2v_embedding_file)\n",
    "print(f\"w2v_emb_matrix:\\t\\t{w2v_emb_matrix.shape}\")\n",
    "print(f\"w2v_word2idx shape:\\t{len(w2v_word2idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare data:\n",
    "- Load the sentences from the tsv files.\n",
    "- Unify sentences (lower case, remove punctuation, etc.).\n",
    "- Split sentences into words.\n",
    "- Cut and zero pad sentences.\n",
    "- Map words to indices.\n",
    "- Map string labels to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:\t\t(5976, 128)\n",
      "x_validation shape:\t(752, 128)\n",
      "x_test shape:\t\t(736, 128)\n",
      "y_train shape:\t\t(5976, 7)\n",
      "y_validation shape:\t(752, 7)\n",
      "y_test shape:\t\t(736, 7)\n"
     ]
    }
   ],
   "source": [
    "def read_tsv(tsv, word2idx, oov_id=1, pad_id=0, seq_length=128):\n",
    "    read_content: list[str] = []\n",
    "    with open(tsv, 'rb') as vecfile:\n",
    "        for line in vecfile.readlines():\n",
    "            read_content.append(str(line))\n",
    "    content = list(map(lambda line: line.split('\\\\t'), read_content))\n",
    "    label_content = [row.pop(1) for row in content]\n",
    "    \n",
    "    content = [[re.sub(r'^b|[^\\w\\s]|\\\\r|\\\\t', '', re.sub(r'\\\\n|\\\\r|\\\\t', '', string.lower().strip())) for string in row] for row in content]\n",
    "    label_content = [re.sub(r'^b|[^\\w\\s]|\\\\r|\\\\t', '', re.sub(r'\\\\n|\\\\r|\\\\t', '', string.lower().strip())) for string in label_content]\n",
    "    \n",
    "    content = [[string.split(' ') for string in row] for row in content]\n",
    "    content = [item for sublist in content for item in sublist]\n",
    "\n",
    "    content = [[word2idx.get(string, oov_id) for string in row] for row in content]\n",
    "    content = [equal_length(sequence, seq_length, pad_id) for sequence in content]\n",
    "    data_x = np.array(content, dtype=np.int32)\n",
    "\n",
    "    unique_labels = set(label_content)\n",
    "    num_labels = len(unique_labels)\n",
    "    temp_label_dict = [{value: index} for index, value in enumerate(unique_labels)]\n",
    "    label_dict: dict[str, int] = {}\n",
    "    for key_value in temp_label_dict:\n",
    "        label_dict.update(key_value)\n",
    "    \n",
    "    label_content = [label_dict[string] for string in label_content]\n",
    "\n",
    "    return data_x, to_categorical(label_content, num_classes=num_labels)\n",
    "\n",
    "def equal_length(sequence: list[int], desired_length: int, padding_id: int):\n",
    "    current_length = len(sequence)\n",
    "    if current_length < desired_length:\n",
    "        sequence.extend(padding_id for i in range(desired_length - current_length))\n",
    "    elif current_length > desired_length:\n",
    "        sequence = sequence[:desired_length]\n",
    "    return sequence\n",
    "\n",
    "\n",
    "train_X, train_y = read_tsv(train_tsv, w2v_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "val_X, val_y = read_tsv(val_tsv, w2v_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "test_X, test_y = read_tsv(test_tsv, w2v_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "\n",
    "# convert labels from string to int\n",
    "\n",
    "print(f\"x_train shape:\\t\\t{train_X.shape}\")\n",
    "print(f\"x_validation shape:\\t{val_X.shape}\")\n",
    "print(f\"x_test shape:\\t\\t{test_X.shape}\")\n",
    "print(f\"y_train shape:\\t\\t{train_y.shape}\")\n",
    "print(f\"y_validation shape:\\t{val_y.shape}\")\n",
    "print(f\"y_test shape:\\t\\t{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialise, train  and evaluate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         12000600  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 128)         186880    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 12,287,199\n",
      "Trainable params: 286,599\n",
      "Non-trainable params: 12,000,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Embedding(input_dim=len(w2v_word2idx.keys()) + 2, output_dim=300, mask_zero=True, \n",
    "              embeddings_initializer=keras.initializers.Constant(w2v_emb_matrix), trainable=False),\n",
    "    Bidirectional(LSTM(64, return_sequences=True, dropout=0.5)),\n",
    "    Bidirectional(LSTM(64, dropout=0.5)),\n",
    "    Dense(7, activation='softmax')]\n",
    ")\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr), metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0ca368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [32,7] and labels shape [224]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-11-5ef8bfcfd7af>:1) ]] [Op:__inference_train_function_55474]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Franz\\OneDrive\\Uni\\DeepLearning\\DL_Exercise\\Git_repo\\08_dl_tut_for_submission.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000016?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_X, y\u001b[39m=\u001b[39;49mtrain_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_X, val_y))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [32,7] and labels shape [224]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-11-5ef8bfcfd7af>:1) ]] [Op:__inference_train_function_55474]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_X, y=train_y, epochs=5, batch_size=32, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=test_X, y=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. EWE embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './res/data/embeddings/ewe-40k-wiki-news-300d.vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Franz\\OneDrive\\Uni\\DeepLearning\\DL_Exercise\\Git_repo\\08_dl_tut_for_submission.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000009?line=0'>1</a>\u001b[0m ewe_emb_matrix, ewe_word2idx \u001b[39m=\u001b[39m read_embedding_matrix(ewe_embedding_file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000009?line=1'>2</a>\u001b[0m train_X, train_y \u001b[39m=\u001b[39m read_tsv(train_tsv, ewe_word2idx, oov_id\u001b[39m=\u001b[39moov_id, pad_id\u001b[39m=\u001b[39mpad_id, seq_length\u001b[39m=\u001b[39mseq_length)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000009?line=2'>3</a>\u001b[0m val_X, val_y \u001b[39m=\u001b[39m read_tsv(val_tsv, ewe_word2idx, oov_id\u001b[39m=\u001b[39moov_id, pad_id\u001b[39m=\u001b[39mpad_id, seq_length\u001b[39m=\u001b[39mseq_length)\n",
      "\u001b[1;32mc:\\Users\\Franz\\OneDrive\\Uni\\DeepLearning\\DL_Exercise\\Git_repo\\08_dl_tut_for_submission.ipynb Cell 4'\u001b[0m in \u001b[0;36mread_embedding_matrix\u001b[1;34m(embedding_file, init_random)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000003?line=1'>2</a>\u001b[0m read_content: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39m# This seems a rather lenghty approach\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000003?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(embedding_file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m vecfile:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000003?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m vecfile\u001b[39m.\u001b[39mreadlines():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Franz/OneDrive/Uni/DeepLearning/DL_Exercise/Git_repo/08_dl_tut_for_submission.ipynb#ch0000003?line=6'>7</a>\u001b[0m         read_content\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(line))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './res/data/embeddings/ewe-40k-wiki-news-300d.vec'"
     ]
    }
   ],
   "source": [
    "ewe_emb_matrix, ewe_word2idx = read_embedding_matrix(ewe_embedding_file)\n",
    "print(f\"ewe_emb_matrix:\\t\\t{ewe_emb_matrix.shape}\")\n",
    "print(f\"ewe_word2idx shape:\\t{len(ewe_word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295008ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ewe = Sequential()\n",
    "model_ewe.add(Embedding(ewe_emb_matrix.shape[0], ewe_emb_matrix.shape[1], weights=[ewe_emb_matrix], mask_zero=True, trainable=False, input_length=128))\n",
    "model_ewe.add(Bidirectional(LSTM(64, dropout=0.5, return_sequences=True)))\n",
    "model_ewe.add(Bidirectional(LSTM(64, dropout=0.5)))\n",
    "model_ewe.add(Dense(7, activation='softmax'))\n",
    "model_ewe.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "model_ewe.summary()\n",
    "\n",
    "model_ewe.fit(x=train_X, y=train_y, validation_data=(val_X, val_y), batch_size=32, epochs=5)\n",
    "\n",
    "model_ewe.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Custom word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_emb_matrix, rand_word2idx = read_embedding_matrix(w2v_embedding_file, True)\n",
    "print(f\"rand_emb_matrix:\\t\\t{rand_emb_matrix.shape}\")\n",
    "print(f\"rand_word2idx shape:\\t\\t{len(rand_word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rand = Sequential()\n",
    "model_rand.add(Embedding(rand_emb_matrix.shape[0], rand_emb_matrix.shape[1], weights=[rand_emb_matrix], mask_zero=True, input_length=128))\n",
    "model_rand.add(Bidirectional(LSTM(64, dropout=0.5, return_sequences=True)))\n",
    "model_rand.add(Bidirectional(LSTM(64, dropout=0.5)))\n",
    "model_rand.add(Dense(7, activation='softmax'))\n",
    "model_rand.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
    "model_rand.summary()\n",
    "\n",
    "model_rand.fit(x=train_X, y=train_y, validation_data=(val_X, val_y), batch_size=32, epochs=5)\n",
    "\n",
    "model_rand.evaluate(test_X, test_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
