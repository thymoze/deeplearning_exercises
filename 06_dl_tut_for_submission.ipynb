{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - DL Tutorial 06\n",
    "\n",
    "### student names:\n",
    "\n",
    "Submit you solution by 16 June 23:59 to manuel.milling@informatik.uni-augsburg.de OR maurice.gerczuk@informatik.uni-augsburg.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from os.path import basename\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Conv2D, MaxPooling2D, BatchNormalization, Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_speakers = [\"03\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\"]\n",
    "train_speakers = [\"03\", \"08\", \"09\", \"10\", \"11\"]\n",
    "validation_speakers = [\"12\", \"13\"]\n",
    "test_speakers = [\"14\", \"15\", \"16\"]\n",
    "data_path = \"emodb/wav/\"\n",
    "label_dict = {\"A\" : 0, \"F\": 1, \"L\": 2, \"N\": 3, \"T\": 4, \"W\": 5, \"E\": 6}\n",
    "num_classes = len(label_dict.keys())\n",
    "cutoff_length = 4 #s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare data and labels by cutting/zero-padding to 4 seconds, extracting spectrograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(data_path + \".wav\")\n",
    "files.sort\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "\n",
    "for file in files:\n",
    "    filename = basename(file)\n",
    "    speaker_id = filename[0:2]\n",
    "    label_num = label_dict[filename[5]]\n",
    "    signal, sr = librosa.load(file)\n",
    "    signal_len = signal.shape[0]\n",
    "    if signal_len < cutoff_length * sr:                \n",
    "        signal = np.concatenate((signal, np.zeros(cutoff_length * sr - signal_len)))    \n",
    "    signal = signal[0:cutoff_length * sr]\n",
    "    melspectrogram = librosa.feature.melspectrogram(y = signal)\n",
    "    log_melspectrogram = librosa.power_to_db(melspectrogram)\n",
    "\n",
    "    log_melspectrogram = np.expand_dims(log_melspectrogram, 2)\n",
    "    \n",
    "    if speaker_id in train_speakers:\n",
    "        x_train.append(log_melspectrogram)\n",
    "        y_train.append(label_num)\n",
    "    elif speaker_id in validation_speakers:\n",
    "        x_validation.append(log_melspectrogram)\n",
    "        y_validation.append(label_num)\n",
    "    else:\n",
    "        x_test.append(log_melspectrogram)\n",
    "        y_test.append(label_num)\n",
    "\n",
    "x_train = np.stack(x_train)\n",
    "x_validation = np.stack(x_validation)\n",
    "x_test = np.stack(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_validation = np.array(y_validation)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_validation = tf.keras.utils.to_categorical(y_validation, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train shape:\\t\\t{}\".format(x_train.shape))\n",
    "print(\"x_validation shape:\\t{}\".format(x_validation.shape))\n",
    "print(\"x_test shape:\\t\\t{}\".format(x_test.shape))\n",
    "print(\"y_train shape:\\t\\t{}\".format(y_train.shape))\n",
    "print(\"y_validation shape:\\t{}\".format(y_validation.shape))\n",
    "print(\"y_test shape:\\t\\t{}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement CNN-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train model with early stopping. Evaluate on test data and plot the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcbf74e6599b59c89045a45bc4482e7ab975fc3adc73df3aaa119394cf55b940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
